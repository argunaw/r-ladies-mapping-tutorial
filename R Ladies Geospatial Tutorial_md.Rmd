---
title: R Ladies Geospatial Tutorial_md.ipynb"
output: html_document
---

```{r}
library(rgdal) ###used for projections and importing data
library(ggplot2) ##creating the map
library(sf) ## data is stored as sf dataframes
library(data.table)
library(dplyr) ##data transformations
library(RColorBrewer) #color palettes
library(stringr) ##string manipulation when filtering dataframes
library(ggthemes) ##map design
library(magrittr) ##pipes
library(classInt) ##intervals for legend
library(grDevices) ### added for export to PDF
library(tmap) ###interactive mapping
```

### Importing Shapefile Data, Projecting, and Converting to R SF format

There are two ways you can download data:

1. Manually download

2. Get URL for download and do all processing in R


### Since the file names are so long and complicated, the process will be as follows:

- download the file

- unzip

- create a subfolder to process and rename the files in

- rename the file

- create a final folder where the processed and renamed files will go

#### First, Let's Create the Directions We'll Be Downloading the Data in To, Cleaning the Data In,
### and then the Final Folder

```{r}
#### destination for all unzipped folders

zip_dl = "C:/Users/argun/Documents/Shapefiles/NYC/Testing"


##create a temporary folder to unzip (only do this once, not for every file)
###note that every folder here is already on my hard drive EXCEPT the folder at the end of string. if the entire string is a series of new folders, you need to add recursive=TRUE
temp_folder= paste0(zip_dl, "/temp")
dir.create(temp_folder)

###final folder for all shapefiles
###create new folder (only do this once, not for every file)
new_dir <-  paste0(zip_dl, "/shps")
dir.create(new_dir)




```

### Boroughs - Download

```{r}


###the open data shapefiles don't have clear names, so we need to do some pre-processing
###download the data (these are the borough boundaries)
download.file("https://data.cityofnewyork.us/api/geospatial/tqmj-j8zm?method=export&format=Shapefile", 
              destfile = paste0(zip_dl, "/boroughs.zip"),
              mode = "wb")

##unzip the folder
unzip("C:/Users/argun/Documents/Shapefiles/NYC/Testing/boroughs.zip",
      exdir=temp_folder)

###we know all the downloads have the file pattern of "geo" with several characters after
old_files <- list.files(temp_folder, full.names = TRUE)
old_files

```

### Boroughs - Cleaning the Files

```{r}
# rename the download
new_names = gsub("^.*?\\.","boroughs.",old_files)



##move unzipped and clean files to a new folder
file.copy(from=old_files, to=paste0(new_dir, "/", new_names))
file.remove(old_files)


###let's check out the new files
list.files(new_dir)
```


### NYC Neighborhoods (NTAs)
#### note: we are going to use the parks subset of this dataset eventually

```{r}
####NTAS, eventually derive parks from this
download.file("https://data.cityofnewyork.us/api/geospatial/d3qk-pfyz?method=export&format=Shapefile", 
              destfile = paste0(zip_dl, "/ntas.zip"),
              mode = "wb")

unzip(paste0(zip_dl, "/ntas.zip"),
      exdir=temp_folder)

old_files <- list.files(temp_folder, pattern = "geo*", full.names = TRUE)

new_names = gsub("^.*?\\.","ntas.",old_files)

file.copy(from=old_files, to=paste0(new_dir, "/", new_names))
file.remove(old_files)
list.files(new_dir)
```

### Read in All Those Shapefiles

```{r}
###read in and project shapefiles to 2263

boroughs <- st_transform(st_read(new_dir, "boroughs" ), 2263)
ntas <- st_transform(st_read(new_dir, "ntas"), 2263)
parks = ntas %>% filter(str_detect(ntaname, paste0("park", collapse = "|")))
gc()
```

### Working With CSVs

#### csvs require a different type of processing; shapefiles are inherent spatial, excel files need to be converted
#### since csvs are not downloaded in a zip file, there is less processing involved

### Open Restaurant Applications - Download

```{r}
###download the csv

download.file("https://data.cityofnewyork.us/api/views/pitm-atqc/rows.csv?accessType=DOWNLOAD&bom=true&format=true", 
              destfile = "C:/Users/argun/Documents/Shapefiles/NYC/Testing/open_restaurants.csv",
              mode = "wb")

```

### Import and Process the Data

```{r}
### import the csv
rest <- fread("C:/Users/argun/Documents/Shapefiles/NYC/Testing/open_restaurants.csv", header = TRUE)
colnames(rest)
```

```{r}
###remove rows without lat/long data
rest <-  rest[!is.na(rest$Latitude) | !is.na(rest$Longitude), ]

###make the imported table in to a sf dataframe
rest_sf <- st_as_sf(rest , coords = c("Longitude", "Latitude"))

### remove old file
rm(rest)
colnames(rest_sf)
```



### We've made it spatial, but let's check the coordinate system and see what it looks like plotted

```{r}
##check coordinate system
st_crs(rest_sf)
```

```{r}
### now let's see what it looks like
###uncomment boroughs to show that you cannot have two datasets with conflicting projections
ggplot()+
  geom_sf(data = rest_sf, color="black", size=.8)#+
  #geom_sf(data = boroughs, color="lightgrey")
```

### Why does the above data look distorted? Because we haven't assigned a coordinate system. Let's do that now

```{r}
st_crs(rest_sf)$IsGeographic ##to check is the CRS is geographic or not
st_crs(rest_sf)$units_gdal ##to find out the CRS units
st_crs(rest_sf)$srid ##extracts its ‘SRID’ identifier (when available)
st_crs(rest_sf)$proj4string ##extracts the proj4string representation
```


### Let's See What Happens When We Set the Coordinate Reference System

```{r}
### set coordinate reference system
###World Geodetic System, 99% of GPS systems use this, I have yet to use data that doesn't
sf_proj <- st_set_crs(rest_sf, value = 4326)
ggplot()+
  geom_sf(data = sf_proj, color="black", size=.8)

```

### No Longer Distorted, But We Can't Measure Distances Without a Projection

```{r}
st_crs(sf_proj)$units_gdal ##to find out the CRS units
```

### In Order to Properly Measure Distances, We Need to Project the Data to the Correct Geographic Area

```{r}
### set projection
sf_proj <- st_transform(sf_proj, "EPSG: 2263")

##check units
st_crs(sf_proj)$units_gdal ##to find out the CRS units
st_crs(sf_proj)$srid ##extracts its ‘SRID’ identifier (when available)
st_crs(sf_proj)$proj4string ##extracts the proj4string representation
rm(rest_sf)
```

## Now That The Geospatial Processing is Done, We Can Clean the Data as Needed

### Check for duplicates

```{r}
sf_proj %>% 
  group_by(objectid) %>% 
  filter(n()>1)
```

### Remove Duplicates

```{r}
rests_sf <- unique(sf_proj, by = "objectid") ## sf version for spatial join
rm(sf_proj)
gc()

```




### Create a simple map using ggplot2 syntax

How do you think this design can be made better?

- add context via parks (explains the gaps)

```{r}
ggplot()+
  geom_sf(data=boroughs, fill=NA, color="black", lwd=.01)+
  geom_sf(data=ntas, fill=NA, color="black", lwd=.002)+
  geom_sf(data=parks, fill="#a1c690", color="darkgrey")+
  geom_sf(data=rests_sf, color="red", size=.2, shape=16)+
  theme(panel.background = element_rect(fill = "white"),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        panel.grid = element_line(color = "white", size = 0.8),
        plot.title= element_text(colour="black", size = 20, face = "bold", hjust=0.5))+
  labs(title = "Open Restaurant Permits \n New York City",
       caption = "Source: NYC Open Data, Retrieved on 2/22/2022")
```

The above map tells shows us the distribution of restaurants across NYC. But what does this mean to the average person? After a certain critical mass of points, you can't visually tell where there are more or less points, or how relevant those points are to the analysis you're trying to do

### We can make what's called a choropleth map, which aggregates points to a geometry and shows meaningful patterns


### Restaurants Grouped by NTA

There are two ways we can do this:

1. since the restaurants file has a NTA column we can use dplyr to get the counts by NTA

2. use a spatial join to count the number of points in polygons


### Note: You CANNOT use dplyr for grouping with spatial objects; even if you group by one column, it automatically also groups by the geometry of each point as well


### Spatial Join Method

Add a column to the ntas data with the count of restaurants.

```{r}
ntas$count_restaurants <- lengths(st_intersects(ntas, rests_sf))
head(ntas)
```


### Normalize the Data and Remove Neighborhoods That Are Outliers

```{r}
###normalize counts
nta_remove = c("cemetery", "Airport") ###list of outliers
airports = c("Airport")


nta_rest <- ntas %>%
filter(!grepl(paste(nta_remove, collapse="|"), ntaname)) %>% ##remove outliers
mutate(rest_sqmi= count_restaurants/(shape_area/27878400))  ###get restaurants per square mile



### keep the airports as a separate df
airports <- ntas %>%
filter(grepl(paste(airports, collapse="|"), ntaname)) 
  
```


### Create a choropleth map from this


We don't want every value in restaurants/sq mile to be a separate value, it doesn't tell us much

```{r}
ggplot(nta_rest) + 
    geom_sf(aes(fill=rest_sqmi))+
    scale_fill_viridis_c(option = "D", na.value = "darkgrey") +
    geom_sf(data=airports, fill="darkgrey")+
    geom_sf(data=parks, fill="#a1c690", color="darkgrey")+
    theme(panel.background = element_rect(fill = "white"),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        panel.grid = element_line(color = "white", size = 0.8),
        plot.title= element_text(colour="black", size = 24, face = "bold", hjust=0.5,))+
  labs(title = "Open Restaurant Permits Per Square Mile \n New York City")
```


```{r}
nta_rest[which(is.na(nta_rest$rest_sqmi)),]
nta_rest[nta_rest$rest_sqmi==0,]
```

### In Order to Better Represent this Data, Let's Add Quantile Breaks

```{r}
### remove NTAs with no restaurants
nta_no_rest <- nta_rest %>%
filter(rest_sqmi==0)

nta_rest <- nta_rest %>%
  filter(rest_sqmi > 0)


### use the "cut" function to add a breaks column in your sf object
nta_rest <- mutate(nta_rest, brks = cut(nta_rest$rest_sqmi, quantile(nta_rest$rest_sqmi, probs = seq(0, 1, .2)), dig.lab = 4)) 

###results include the upper bound but NOT the lower bound!
###let's look at the breaks
unique(nta_rest$brks)
```

```{r}
##map colors
brewer.pal(n=5,"YlOrRd")
colors <- c("#FFFFB2", "#FECC5C", "#FD8D3C", "#F03B20", "#BD0026", "#A1C690", "darkgrey", "black")

```

### To Properly Label Each Element, we need to manually assign each interval to a color
```{r}

ggplot() + 
    geom_sf(data=nta_rest, aes(fill=brks)) +
    geom_sf(data=parks,  aes(fill="Parks/Cemeteries"))+
    geom_sf(data=nta_no_rest, aes(fill="No Restaurants"))+
    geom_sf(data=airports, aes(fill="Airports"))+
    theme(panel.background = element_rect(fill = "white"),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        panel.grid = element_line(color = "white", size = 0.8),
        plot.title= element_text(colour="black", size = 18, face = "bold", hjust=0.5,))+
    scale_fill_manual("Legend",
    values=colors,
    breaks=c(levels(nta_rest$brks), 'Parks/Cemeteries', 'No Restaurants', 'Airports'))+
  labs(title = "Open Restaurant Permits \nPer Square Mile \nby Neighborhood Tabulation Area",
       caption="source: NYC Open Data, Retrieved on 2/24/2022")
  
```

### If you save the object as a variable, you can eventually save this as a pdf using the code below

```{r}
#ggsave("test_map_rest.pdf",
#       plot=saved_map_variable,
#       width=8.5, height=11, units="in",
#       dpi=1200)
#unlink("test_map_rest.pdf")
```

```{r}
#dev.off()
```

###Same map in TMAP: easier syntax

```{r}
tmap_mode("plot")+
tm_shape(nta_rest) +
  tm_polygons("rest_sqmi", 
              style="quantile", 
              legend.format = list(text.separator="-", fun = function(x) formatC(x, digits = 2, big.mark = ",", format = "f")) ,
              title="New York City\nOpen Restaurant Permits \nper Square Mile")+
tm_shape(nta_no_rest)+
  tm_polygons(col = "darkgrey") +
tm_shape(airports)+
  tm_polygons(col="black")+
tm_shape(parks)+
  tm_polygons(col="#a1c690", border.col = "darkgrey")

```

###Interactive Map


```{r}
tmap_mode("view")
tm_shape(ntas)+
  tm_polygons(col="white", alpha = .25)+
tm_shape(rests_sf)+
  tm_symbols(shape=21, col="red", size = .0005,
  popup.vars=c("Restaurant Name"="Restaurant Name", "Seating Interest (Sidewalk/Roadway/Both)"="Seating Interest (Sidewalk/Roadway/Both)"))
```
